{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2591f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer ,TfidfTransformer, CountVectorizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score ,roc_auc_score , classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93aa020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\Telegram Desktop\\spam.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16ecc43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9967899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= dataset.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "914dfb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "614e5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns = {'v1':'Category', 'v2':'Text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8568bd",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e004dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Category', ylabel='count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='Category', data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6166410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    U dun say so early hor... U c already then say...\n",
       "4    Nah I don't think he goes to usf, he lives aro...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = dataset[\"Text\"] \n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f349f3",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3757ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDataset(train_text):\n",
    "       \n",
    "    #word tokenization using text-to-word-sequence\n",
    "    train_text= str(train_text)\n",
    "    tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
    "        \n",
    "    #stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "        \n",
    "     \n",
    "    #join words into sentence\n",
    "    stopwordremove_text = ' '.join(stopwordremove)\n",
    "        \n",
    "        \n",
    "    #remove numbers\n",
    "    numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "       \n",
    "        \n",
    "    #--Stemming--\n",
    "    stemmer= PorterStemmer()\n",
    "\n",
    "    stem_input=nltk.word_tokenize(numberremove_text)\n",
    "    stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "        \n",
    "        \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def get_wordnet_pos(word):\n",
    "\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    lem_input = nltk.word_tokenize(stem_text)\n",
    "    lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "        \n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06f21ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazi avail bugi n great world...\n",
       "1                                ok lar joke wif u oni\n",
       "2    free entri wkli comp win fa cup final tkt st m...\n",
       "3                  u dun say earli hor u c alreadi say\n",
       "4                 nah think goe usf live around though\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Text'] = dataset['Text'].apply(preprocessDataset)\n",
    "text = dataset['Text']\n",
    "category = dataset['Category']\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce72dc",
   "metadata": {},
   "source": [
    "## Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de3fe67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900\n",
      "1672\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(text,category, test_size = 0.3, random_state = 60,shuffle=True, stratify=category)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00cf8cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630                           plea dont say like hi hi hi\n",
       "374     thank rington order refer t charg gbp per week...\n",
       "3814     yet chikku k wat abt tht guy stop irrit msging u\n",
       "4762                                       prepar pleasur\n",
       "155                                      aaooooright work\n",
       "                              ...                        \n",
       "981                reckon need town eightish walk carpark\n",
       "937                                            k k colleg\n",
       "5077    want new nokia i colour phone deliveredtomorro...\n",
       "4629                              everybodi fun even miss\n",
       "3674                                            who class\n",
       "Name: Text, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fc38083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681     ham\n",
       "5532    ham\n",
       "670     ham\n",
       "4682    ham\n",
       "4996    ham\n",
       "       ... \n",
       "3783    ham\n",
       "1170    ham\n",
       "593     ham\n",
       "3245    ham\n",
       "739     ham\n",
       "Name: Category, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20eeed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Train Accuracy Score : 99% \n",
      "Naive Bayes Test Accuracy Score  : 97% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "               ('clf', BernoulliNB(binarize=0.0)),\n",
    "              ])\n",
    "nb.fit(X_train,Y_train)\n",
    "\n",
    "test_predict = nb.predict(X_test)\n",
    "\n",
    "train_accuracy = round(nb.score(X_train,Y_train)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"Naive Bayes Test Accuracy Score  : {}% \".format(test_accuracy ))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c8af747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.97      0.98      1490\n",
      "        spam       0.80      0.99      0.89       182\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.90      0.98      0.94      1672\n",
      "weighted avg       0.98      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_category = dataset['Category'].unique()\n",
    "print(classification_report(test_predict, Y_test, target_names=target_category))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
